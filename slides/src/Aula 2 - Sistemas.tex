\documentclass{beamer}
\usetheme[logo=brasaoUFSC.png]{fibeamer}
%% These macros specify information about the presentation
\title{Aula 2: Sistemas}
%\subtitle{2019.2}
\author{Melissa Weber Mendonça}
%% These additional packages are used within the document:
\usepackage{ragged2e}  % `\justifying` text
\usepackage{booktabs}  % Tables
\usepackage{tabularx}
\usepackage{tikz}      % Diagrams
\usetikzlibrary{calc, shapes, backgrounds, }
\usepackage{pgfplots}
\usepackage{amsmath, amssymb}
\usepackage{url}       % `\url`s
\usepackage{listings}  % Code listings
\usepackage{verbatim}
\usepackage{animate}
\usepackage{hyperref}
\hypersetup{
    colorlinks = true,
    allcolors = [rgb]{1,0.83,0.39}
}
\frenchspacing

\makeatletter
\setlength\fibeamer@lengths@logowidth{4em}
\setlength\fibeamer@lengths@logoheight{5em}
\makeatother

\begin{document}
\frame{\maketitle}

\begin{darkframes}

\begin{frame}{Produto entre matrizes}
    Podemos encarar o produto de duas matrizes de forma monolítica, mas existem outros jeitos de interpretarmos esta operação.
 \begin{itemize}
     \item<2->[(i)] Cada entrada da matriz-produto $AB$ é o produto entre uma linha e uma coluna:
     \begin{equation*}
         (AB)_{ij} = \mbox{ linha } i \mbox{ de } A \mbox{ vezes a coluna } j \mbox{ de } B
     \end{equation*}
     \item<3->[(ii)] Cada coluna de $AB$ é o produto entre uma matriz e uma coluna:
     \begin{equation*}
         \mbox{coluna } j \mbox{ de } AB = A \mbox{ vezes coluna } j \mbox{ de } B
     \end{equation*}
     \item<4->[(iii)] Cada linha de $AB$ é o produto entre uma linha e uma matriz:
     \begin{equation*}
         \mbox{linha } i \mbox{ de } AB = \mbox{ linha } i \mbox{ de } A \mbox{ vezes } B.
     \end{equation*}
 \end{itemize}
\end{frame}

\begin{frame}{Exemplo}
  \begin{equation*}
     \begin{bmatrix}
       1 & 0\\
       2 & 3
     \end{bmatrix}
     \begin{bmatrix}
       2 & 1\\
       3 & 4
     \end{bmatrix}
     = 
     \only<2>{\begin{bmatrix}
       1\cdot 2+0\cdot 3 & 1\cdot 1+0\cdot 4\\
       2\cdot 2+3\cdot 3 & 2\cdot 1+3\cdot 4
     \end{bmatrix}}
    \only<3>{%
    \begin{bmatrix}
      \begin{bmatrix}
        1 & 0\\
        2 & 3
      \end{bmatrix}
      \begin{bmatrix}
        2\\3
      \end{bmatrix}
      &
      \begin{bmatrix}
        1 & 0\\
        2 & 3
      \end{bmatrix}
      \begin{bmatrix}
        1\\4
      \end{bmatrix}
    \end{bmatrix}}
    \only<4>{%
    \begin{bmatrix}
      \begin{bmatrix}
        1 & 0
      \end{bmatrix}
      \begin{bmatrix}
        2 & 1\\
        3 & 4
      \end{bmatrix}\\
      \begin{bmatrix}
        2 & 3
      \end{bmatrix}
      \begin{bmatrix}
        2 & 1\\
        3 & 4
      \end{bmatrix}
    \end{bmatrix}}
  \end{equation*}
\end{frame}

\begin{frame}{Como resolver sistemas lineares quadrados?}
 Poderíamos resolver um sistema $Ax=b$ encontrando a inversa de $A$, pois se $Ax=b$, então
 \begin{equation*}
 	x = A^{-1}b
 \end{equation*}
 No entanto, encontrar a inversa de uma matriz não é tarefa fácil; assim, vamos procurar resolver o sistema usando outras estratégias.

 \vfill

 \alert{Ideia:} transformar a matriz (quadrada) geral em uma matriz triangular para resolver o sistema linear por substituição.
\end{frame}

\begin{frame}{Forma escalonada: Exemplo}
	\only<1-2>{\begin{equation*}
		\begin{cases} 
        	x+y+2z &= 9\\ 
            2x+4y-3z &= 1\\ 
            3x+6y-5z &= 0 
        \end{cases}
	\end{equation*}}
	\only<2>{Eliminando $x$ na segunda e terceira equações:}
    \only<2-3>{%
	\begin{equation*}
    	\left\{
		\begin{array}{r r r l}
			x &+ y &+ 2z  &=  9\\ 
			  & y &- \frac{7z}{2}  &=  -\frac{17}{2}\\ 
			  &-y &+ \frac{11z}{3} &= 9 
		\end{array}
        \right.
	\end{equation*}}
	
	\only<3>{Agora, vamos eliminar $y$ na terceira equação:}
    \only<3-4>{%
	\begin{equation*}
		\left\{ 
		\begin{array}{r r r l}
			x&+y &+ 2z &= 9\\ 
			 & y &-(7/2)z &= -17/2\\ 
			 &   & (1/6)z &= 1/2 
		\end{array} 
		\right.
	\end{equation*}}
	
    \only<4-5>{Resolvendo para $z$, temos que}
    \only<5>{%
	\begin{equation*}
    	z = 3
    \end{equation*}
	Além disso,
	\begin{equation*}
    	2y - 7z = -17 \Leftrightarrow 2y = -17+21 = 4 \Leftrightarrow y = 2
    \end{equation*}
	Por último,
	\begin{equation*}
    	x+y+2z = 9 \Leftrightarrow x = 9 -2(3)-2 = 9-8 = 1.
    \end{equation*}}
\end{frame}

\begin{frame}{Sistemas Lineares Homogêneos}
Considere o sistema linear
\begin{align*}
    Ax=b \Leftrightarrow 
        \begin{bmatrix}
            a_{11} & a_{12} & \cdots & a_{1n}\\
            a_{21} & a_{22} & \cdots & a_{2n}\\
            \vdots & \vdots & \ddots & \vdots\\
            a_{m1} & a_{m2} & \cdots & a_{mn}
        \end{bmatrix}
        \begin{bmatrix}
            x_1\\
            x_2\\
            \vdots\\
            x_n
        \end{bmatrix}
        =
        \begin{bmatrix}
            b_1\\
            b_2\\
            \vdots\\
            b_m
        \end{bmatrix}
\end{align*}
\vfill
\only<2>{Se $b = 0$, chamamos este sistema de \emph{homogêneo}.}
\end{frame}

\begin{frame}{Sistema homogêneo: Exemplo}
	\begin{equation*}
		\begin{cases}
			x_1 - 2x_2  + x_3 =0\\
			x_1+x_2+x_3=0\\
			x_1  +x_3 = 0
		\end{cases}
	\end{equation*}
	Em forma matricial:
	\begin{equation*}
		\begin{bmatrix}
			x_1 & -& 2x_2 & +&x_3&=&0\\
			x_1&+&x_2&+&x_3&=&0\\
			x_1& & &+&x_3 &=& 0
		\end{bmatrix} \rightarrow 
		\begin{bmatrix}
			x_1 & -& 2x_2 & +&x_3&=&0\\
			 &-&3x_2&&&=&0\\
			&-&2x_2 & & &=& 0
		\end{bmatrix}
	\end{equation*}
	Aqui, podemos ver que, pelas equações acima, $x_2 = 0$, $x_1+x_3 = 0$, ou seja $x_1$ é \emph{livre}, $x_2 = 0$ e $x_3 = -x_1$. Neste caso, o sistema tem infinitas soluções. 
\end{frame}

\begin{frame}{E se não fosse homogêneo?}
	Se, por outro lado, o lado direito for diferente de nulo, teremos:
	\begin{equation*}
		\begin{bmatrix}
			x_1 & -& 2x_2 & +&x_3&=&1\\
			x_1&+&x_2&+&x_3&=&2\\
			x_1& & &+&x_3 &=& 3
		\end{bmatrix} \rightarrow 
		\begin{bmatrix}
			x_1 & -& 2x_2 & +&x_3&=&1\\
			 &-&3x_2&&&=&1\\
			&-&2x_2 & & &=& 2
		\end{bmatrix}
	\end{equation*}
	De onde vemos que o valor de $x_2$ não pode ser encontrado. Portanto, esse sistema é inconsistente.

	No entanto, se tivéssemos
	\begin{equation*}
		\begin{bmatrix}
			x_1 & -& 2x_2 & +&x_3&=&6\\
			x_1&+&x_2&+&x_3&=&-3\\
			x_1& & &+&x_3 &=& 0
		\end{bmatrix} \rightarrow 
		\begin{bmatrix}
			x_1 & -& 2x_2 & +&x_3&=&6\\
			 &-&3x_2&&&=&9\\
			&-&2x_2 & & &=& 6
		\end{bmatrix}
	\end{equation*}
	então o sistema seria consistente, mas teria infinitas soluções.
\end{frame}

\begin{frame}{O que deu errado?}
\begin{center}
    \alert{Pivôs nulos.}
\end{center}

\vfill 

Assim, esse procedimento pode ser usado para identificar classes de sistemas lineares; se o procedimento puder ser realizado até o fim, sabemos que teremos uma solução definida para o sistema.
\end{frame}

\begin{frame}{Forma escalonada}
 \begin{block}{Definição}
   Uma matriz $A$ está na forma escalonada quando:
   {\footnotesize{%
   \begin{itemize}
       \item Se uma linha não for inteiramente nula, o primeiro número não-nulo da linha (indo da esquerda para a direita) é 1 (pivô);
 		\item Se uma linha é nula, ela está abaixo de todas as linhas que contém elementos não-nulos;
 		\item Para cada duas linhas não-nulas, o pivô da de baixo está mais à direita que o da de cima;
 		\item Cada coluna que tem pivô é nula no resto. (se utilizarmos o procedimento de Gauss-Jordan até o final)
   \end{itemize}}}
 \end{block}
Esta definição é válida também para sistemas não quadrados, mas por enquanto vamos nos concentrar em sistemas quadrados. 
\end{frame}

\begin{frame}{Casos}
Para sistemas não-homogêneos:
\begin{itemize}
  \item Se todos os pivôs forem não nulos:
	\begin{itemize} 
		\item sistema consistente e determinado (caso quadrado)
		\item sistema impossível
	\end{itemize}
	\item Se algum pivô for nulo:
	\begin{itemize}
		\item sistema consistente indeterminado (infinitas soluções)
		\item sistema impossível
	\end{itemize}
\end{itemize}
Para o caso homogêneo,
\begin{itemize}
  \item Se todos os pivôs são não-nulos, então a solução trivial é a única solução.
  \item Senão, temos infinitas soluções (sistema indeterminado).
\end{itemize}
\end{frame}

\begin{frame}{Operações elementares}

Nestes exemplos, resolvemos o sistema ao realizarmos as chamadas operações elementares nas linhas nestas matrizes. As operações elementares são:

\begin{itemize}
  \item Multiplicar uma linha por um escalar não-nulo;
  \item Trocar uma linha $r$ do sistema por $r+cs$, onde $c$ é um escalar e $s$ é outra linha do sistema ($r\ne s$);
  \item Trocar duas linhas de lugar.
\end{itemize}

Estas operações são importantes pois podem ser revertidas! Vamos analisar essas operações na forma matricial.
\end{frame}

\begin{frame}{Matrizes elementares}
 \begin{block}{Definição}
   Uma matriz $n\times n$ que pode ser obtida da matriz $I_n$ executando-se uma única operação elementar sobre linhas é uma matriz elementar.
 \end{block}
\vfill
 Se $E$ resulta de uma operação elementar em $I_{m\times m}$ e $A_{m\times n}$, então $EA$ realiza as mesmas operações em $A$.
\end{frame}

\begin{frame}{Exemplo}
	\begin{align*}
		E &= \begin{bmatrix} 1&0&0\\0&1&0\\3&0&1 \end{bmatrix}\\
        A &= \begin{bmatrix} 1&0&2&3\\ 2&-1&3&6\\1&4&4&0\end{bmatrix}\\
        EA &= \begin{bmatrix} 1&0&2&3\\ 2&-1&3&6\\ 4&4&10&9\end{bmatrix}
	\end{align*}
\end{frame} 

\begin{frame}{Teorema}
 \begin{block}{Teorema}
   Toda $E$ elementar é inversível, e $E^{-1}$ também é elementar.
 \end{block}
 \vfill
 \alert{Demonstração}
\only<2->{Seja $E_0$ a matriz que resulta da aplicação da operação elementar
 inversa de $E$ em $I$ (garantida pois estamos em um corpo!!). Então,
 	$$E_0 E = I = EE_0$$
 	$E_0$ também é elementar pois representa também uma operação elementar.}
\end{frame}

\begin{frame}{Exemplo}
	\begin{equation*}
	   A = \begin{bmatrix} 2&1&1\\4&-6&0\\-2&7&2 \end{bmatrix} \qquad b =
\begin{bmatrix} 5\\-2\\9 \end{bmatrix}
	\end{equation*}
	Temos então:
	\only<2>{\begin{align*}
		E^{(1)}  A = A^{(1)} & \Leftrightarrow
		\begin{bmatrix}
			1&0&0\\-2&1&0\\0&0&1
		\end{bmatrix}
		\begin{bmatrix}
			2&1&1\\4&-6&0\\-2&7&2
		\end{bmatrix}
		=
		\begin{bmatrix}
			2&1&1\\0&-8&-2\\-2&7&2
		\end{bmatrix}\\
	  E^{(1)} b = b^{(1)} & \Leftrightarrow 
		\begin{bmatrix}
			1&0&0\\-2&1&0\\0&0&1
		\end{bmatrix}
		\begin{bmatrix}
			5\\-2\\9
		\end{bmatrix}
		=
		\begin{bmatrix}
			5\\-12\\9
		\end{bmatrix}
	\end{align*}}
	\only<3>{\begin{align*}
		E^{(2)} A^{(1)} = A^{(2)} & \Leftrightarrow
		\begin{bmatrix}
			1&0&0\\0&1&0\\1&0&1
		\end{bmatrix}
		\begin{bmatrix}
			2&1&1\\0&-8&-2\\-2&7&2
		\end{bmatrix}
		=
		\begin{bmatrix}
			2&1&1\\0&-8&-2\\0&8&3
		\end{bmatrix}\\
	   E^{(2)} b^{(1)} = b^{(2)} &\Leftrightarrow
		\begin{bmatrix}
			1&0&0\\0&1&0\\1&0&1
		\end{bmatrix}
		\begin{bmatrix}
			5\\-12\\9
		\end{bmatrix}
		=
		\begin{bmatrix}
			5\\-12\\14
		\end{bmatrix}
	\end{align*}}
    \only<4>{%
	\begin{align*}
		E^{(3)} A^{(2)} = A^{(3)} & \Leftrightarrow
		\begin{bmatrix}
			1&0&0\\0&1&0\\0&1&1
		\end{bmatrix}
		\begin{bmatrix}
			2&1&1\\0&-8&-2\\0&8&3
		\end{bmatrix}
		=
		\begin{bmatrix}
			2&1&1\\0&-8&-2\\0&0&1
		\end{bmatrix}\\
	   E^{(3)} b^{(2)} = b^{(3)}&\Leftrightarrow
		\begin{bmatrix}
			1&0&0\\0&1&0\\0&1&1
		\end{bmatrix}
		\begin{bmatrix}
			5\\-12\\14
		\end{bmatrix}
		=
		\begin{bmatrix}
			5\\-12\\2
		\end{bmatrix}
	\end{align*}}
	\only<5>{%
	\begin{align*}
	E & = E^{(3)}E^{(2)}E^{(1)} \\&= 
	\begin{bmatrix}
		1&0&0\\0&1&0\\0&1&1
	\end{bmatrix}
	\begin{bmatrix}
		1&0&0\\0&1&0\\1&0&1
	\end{bmatrix}
	\begin{bmatrix}
			1&0&0\\-2&1&0\\0&0&1
	\end{bmatrix}
	=
	\begin{bmatrix}
		1&0&0\\
		-2&1&0\\
		-1&1&1
	\end{bmatrix}
	\end{align*}}
\end{frame}

\begin{frame}{Objetivos}
 Existem algumas maneiras de representar a matriz depois das operações elementares:
 \begin{itemize}
 \item<1> Se quisermos obter a matriz na forma \emph{escalonada}, realizamos as operações por linhas, de forma que a matriz resultante seja triangular superior com pivôs $1$;
 \item<2> Se quisermos obter a matriz na forma \emph{reduzida por linhas}, realizamos as operações por linhas, de forma que a matriz resultante tenha pivôs $1$, e zero no resto de cada coluna com pivô;
 \item<3> Se quisermos apenas resolver o sistema, realizamos as operações por linhas, de forma que a matriz resultante seja triangular superior com pivôs não-nulos (não necessariamente $1$). Neste caso, obtemos a decomposição (ou fatoração) LU da matriz.
 \end{itemize}
\end{frame}
\begin{frame}{Matrizes Elementares}
 As operações elementares realizadas no momento do escalonamento do sistema podem ser acumuladas em uma matriz $E$, que é o produto das matrizes elementares utilizadas. Assim,
 \begin{equation*}
   EA=U
 \end{equation*}
 e ainda,
 \begin{equation*}
   A = E^{-1}U = LU.
 \end{equation*}
\end{frame}

\begin{frame}{Como isso se relaciona com o sistema?}
	
Podemos agora fazer
\begin{equation*}
	Ax = b \Leftrightarrow LUx = b
\end{equation*}
\vskip-0.5cm
ou seja,
\vskip-0.5cm
\begin{align*}
  \mbox{Resolvemos } Ly = b &\mbox{ para } y;\\
  \mbox{Resolvemos } Ux = y &\mbox{ para } x.
\end{align*}

Felizmente, não precisamos montar as matrizes $E$! 
\begin{itemize}
  \item Reduzir $A$ à forma escalonada $U$, guardando os multiplicadores;
	\item Na diagonal de $L$ colocar 1's;
	\item Abaixo da diagonal de $L$, colocar o negativo do multiplicador usado para zerar o respectivo elemento de $A$.
\end{itemize}
\end{frame}


\begin{frame}{Exemplo}
	\begin{equation*}
	   \begin{bmatrix} 2&1&1\\4&-6&0\\-2&7&2 \end{bmatrix} 
	\end{equation*}

\only<2>{\begin{equation*}
		\begin{bmatrix}
			2&1&1\\4&-6&0\\-2&7&2
		\end{bmatrix}
		=
		\begin{bmatrix}
			1&0&0\\
			2&1&0\\
			-1&-1&1
		\end{bmatrix}
		\begin{bmatrix}
			2&1&1\\
			0&-8&-2\\
			0&0&1
		\end{bmatrix}
	\end{equation*}}
\end{frame}

\begin{frame}{}
\begin{block}{Definição}
  Se $A$ e $B$ são matrizes $m\times n$, dizemos que $A$ é
equivalente por linhas a $B$ se $B$ puder ser obtida através de um
número finito de operações elementares efetuadas em $A$.
\end{block}

 Desta forma, é fácil ver que, como cada operação elementar pode ser
 representada por uma matriz elementar, e como a aplicação sucessiva destas matrizes elementares é representada pelo produto de todas estas matrizes, então 

 \begin{center}
 \framebox[0.85\textwidth]{\parbox{0.8\textwidth}{\centering \emph{$A$ e $B$ são equivalentes por linhas se e somente se $A = PB$, onde $P$ é um produto de matrizes elementares.}}}
 \end{center}
\end{frame}

\begin{frame}{}
 \begin{block}{Teorema}
   Se $A$ e $B$ são equivalentes por linhas, então os sistemas $Ax = 0$ e $Bx = 0$ tem exatamente as mesmas soluções.
\end{block}

\alert{Demonstração}
\only<2>{Basta mostrarmos que uma operação elementar não altera o conjunto de soluções. Mas, note que
	\begin{equation*}
    	EAx = 0 \Leftrightarrow Ax = E^{-1}0 = 0.
    \end{equation*}
	Portanto, $EAx = 0$ tem o mesmo conjunto de soluções que $Ax=0$. Logo, se cada operação elementar não altera o conjunto solução, e aplicamos uma sequência finita de operações elementares em $A$ para chegarmos a $B$, então $Ax=0$ e $Bx=0$ tem o mesmo conjunto de soluções.}
\end{frame}

\begin{frame}{}
\begin{block}{Teorema}
  Se $A$ é $n\times n$, então sua forma reduzida por linhas escalonada (escalonada, em que cada coluna que contém um pivô é nula em todas as outras entradas) terá ao menos uma linha toda nula, ou será a matriz identidade.
\end{block}
\end{frame}
\begin{frame}{Demonstração}
\only<1>{%
Suponha que $B$ é a forma reduzida por linhas escalonada da matriz. Se $B$ tiver pelo menos uma linha toda nula então não há nada a provar. Suponha desta forma que $B$ não tem uma linha toda nula. Então, toda linha deve ter um 1.}
\only<2->{Toda linha tem um 1.}

\only<3>{Sabemos que o 1 de uma linha deve estar à esquerda do 1 da linha de baixo. Suponha então que o 1 da primeira linha não está em $b_{11}$, mas em $b_{12}$. No melhor caso, cada 1 da linha 2 em diante está uma posição à direita do 1 da linha de cima. Então, na linha 2 o primeiro 1 deve estar pelo menos em $b_{23}$, e o de baixo em $b_{34}$ e assim por diante, até que, na linha $n-1$, teremos $b_{n-1,n} = 1$. Desta forma, na última linha não teremos a posição $b_{n,n+1}$ para colocar o próximo 1, e esta linha deve ficar nula, o que contradiz nossa hipótese. Se tomarmos um caso pior ainda, em que o 1 de uma linha está mais de uma casa deslocado para a direita, acabaremos com mais linhas nulas, o que também confirma nosso teorema.}
\only<4->{O 1 da primeira linha em que estar em $b_{11}$.}

\only<5>{Podemos concluir o mesmo para todos os outros elementos não nulos da forma reduzida por linhas escalonada de $A$.}
\end{frame}

\begin{frame}{}
\begin{block}{Corolário}
   Toda $A_{n\times n}$ pode ser reduzida à forma escalonada (reduzida
 por linhas, ou reduzida por linhas escalonada).
 \end{block}
\alert{Demonstração}
   Segue direto da definição de matriz reduzida por linhas escalonada, já que podemos ter inclusive linhas nulas. Todas as outras operações estão bem definidas para quaisquer entradas da matriz $A$.
\end{frame}

\begin{frame}{}
\begin{block}{Teorema}
   {\footnotesize{Se $A$ é uma matriz $n\times n$ então as seguintes afirmações são equivalentes:
   \begin{itemize}
       \item[(a)] $A$ é inversível;
       \item[(b)] A única solução para o sistema homogêneo $Ax=0$ é a solução trivial;
       \item[(c)] $A$ é equivalente por linhas a $I$; 
       \item[(d)] $A$ pode ser expressa como um produto de matrizes elementares.
   \end{itemize}}}
 \end{block}
\alert{Demonstração}
\only<1>{\begin{itemize}
   \item[(a) $\Rightarrow$ (b)] Suponha que $A$ é inversível, vamos mostrar então que $Ax=0$ só possui a solução trivial. Suponha que $x_0$ é uma solução deste sistema. Como $A$ é inversível, basta vermos que $A^{-1}Ax_0 = A^{-1}0 = 0$, ou seja $x_0 = 0$. 
   \end{itemize}}
  \only<2>{\begin{itemize}\item[(b) $\Rightarrow$ (c)] Primeiramente, escrevemos a matriz aumentada deste sistema, $[A | 0]$. Agora, como sabemos que a única solução deste sistema é a solução trivial, então podemos reduzir $A$ à forma reduzida por linhas escalonada que nos dá essa solução, ou seja, $A$ deve ser equivalente por linhas a $I$. \end{itemize}}
  \only<3>{\begin{itemize}\item[(c) $\Rightarrow$ (d)] Como $A$ é equivalente por linhas a $I$, sabemos que pode-se escrever
  $$E_kE_{k-1}\ldots E_2E_1 A = I$$
  Como já mostramos que as matrizes elementares são inversíveis, isto nos dá
  $$A = E_1^{-1}E_2^{-1}\ldots E_{k-1}^{-1}E_k^{-1}.$$\end{itemize}}
  \only<4>{\begin{itemize}\item[(d) $\Rightarrow$ (a)] Se $A$ é um produto de matrizes inversíveis, e como mostramos que tal produto é inversível também, então $A$ deve ser inversível.\end{itemize}}
\end{frame}

\begin{frame}{Fatoração $LU$}
 Vamos considerar uma situação que não tínhamos considerado antes: a troca de linhas.
	\begin{equation*}
	   \begin{bmatrix}
	      0 & 2\\
	      3 & 4
	   \end{bmatrix}
	\end{equation*}
Temos:
\begin{equation*}
	   PA = \begin{bmatrix} 0 & 1\\1& 0 \end{bmatrix} \begin{bmatrix} 0 & 2\\3 &
4 \end{bmatrix} = \begin{bmatrix} 3 & 4\\ 0 & 2\end{bmatrix}
	\end{equation*}
	que, inclusive, já está na forma escalonada! Portanto, podemos reescrever esta situação como
	\begin{equation*} 
		PA = LU.
	\end{equation*}
\end{frame}

\begin{frame}{Exemplo}
	\begin{equation*}
  \begin{bmatrix}
      1 & 1 & 1 & \_ \\
      2 & 2 & 5 & \_ \\
      4 & 6 & 8 & \_
  \end{bmatrix}
  \rightarrow 
  \begin{bmatrix}
      1 & 1 & 1 & \_ \\
      0 & 0 & 3 & \_ \\
      0 & 2 & 4 & \_
  \end{bmatrix}
  \rightarrow 
  \begin{bmatrix}
      1 & 1 & 1 & \_ \\
      0 & 2 & 4 & \_ \\
      0 & 0 & 3 & \_ 
  \end{bmatrix}
	\end{equation*}
\end{frame}

\begin{frame}{Exemplo}
  \begin{equation*}
  \begin{bmatrix}
      1 & 1 & 1 & \_ \\
      2 & 2 & 5 & \_ \\
      4 & 4 & 8 & \_
  \end{bmatrix}
  \rightarrow 
  \begin{bmatrix}
      1 & 1 & 1 & \_ \\
      0 & 0 & 3 & \_ \\
      0 & 0 & 4 & \_
  \end{bmatrix}
	\end{equation*}
	Não há permutação que permita encontrar um pivô.
\end{frame}

\begin{frame}{Observação}
 A matriz de permutação é sempre a identidade com linhas trocadas. Desta forma, uma sequência de permutações consecutivas pode ser encontrada através do produto das permutações, assim como havíamos feito com as operações elementares.
\end{frame}
\end{darkframes}
\end{document}

